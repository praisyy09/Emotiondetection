# -*- coding: utf-8 -*-
"""EmotionDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KfrV9Gxn0bGdoa5lECnxzsVjIIyIaoow
"""

pip install tensorflow opencv-python matplotlib

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt

# Image data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
)

val_datagen = ImageDataGenerator(rescale=1./255)

# Load training data
train_data = train_datagen.flow_from_directory(
    directory="/content/archive/train",
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# Load validation data
val_data = val_datagen.flow_from_directory(
    directory="/content/archive/test",
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# Define the model
model = Sequential()

# First convolutional layer
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Second convolutional layer
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Third convolutional layer
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Flatten the output
model.add(Flatten())

# Fully connected layer
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))  # Regularization to prevent overfitting
model.add(Dense(7, activation='softmax'))  # Adjust the output to match the number of classes

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

from keras.callbacks import EarlyStopping

es = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, mode='max', restore_best_weights=True)

history = model.fit(
    train_data,
    steps_per_epoch=train_data.samples // train_data.batch_size,
    epochs=30,
    validation_data=val_data,
    validation_steps=val_data.samples // val_data.batch_size,
    callbacks=[es]  # Add early stopping callback
)

# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Load an image
img_path = "/content/train/train/Sad/download.jpg"
img = load_img(img_path, target_size=(224, 224))
img_array = img_to_array(img) / 255.0  # Normalize the image
input_arr = np.expand_dims(img_array, axis=0)  # Expand dimensions to match the model input

# Predict the class
pred = model.predict(input_arr)
pred_class = np.argmax(pred)

# Map class index to class name
class_indices = train_data.class_indices
class_labels = list(class_indices.keys())
predicted_label = class_labels[pred_class]

print(f"The image is classified as: {predicted_label}")

# Display the image
plt.imshow(img_array)
plt.title("Input Image")
plt.axis('off')
plt.show()